{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "codex_tags = {\n",
    "}\n",
    "\n",
    "from codex_widget_factory import utils\n",
    "results_json=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "step_1 = \"\"\"\n",
    "# Below codestring is used to perform detailed analysis on quantity of sales done over time. \n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import json\n",
    "from io import StringIO\n",
    "import plotly.io as io\n",
    "\n",
    "\n",
    "def getLogger():\n",
    "    import logging\n",
    "    logging.basicConfig(filename=\"UIACLogger.log\",\n",
    "                        format='%(asctime)s %(message)s',\n",
    "                        filemode='a')\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    return logger\n",
    "\n",
    "\n",
    "logger = getLogger()\n",
    "\n",
    "\n",
    "def fiile_read(blob_name):\n",
    "    #reading the file from azure blob storage container\n",
    "    logger.info(f\"Read dataset file: {blob_name}\")\n",
    "    try:\n",
    "        from azure.storage.blob import BlockBlobService\n",
    "        sas_token = '?sv=2021-04-10&st=2022-12-22T08%3A12%3A47Z&se=2023-12-30T08%3A12%3A00Z&sr=c&sp=racwl&sig=fMeYkXsCvwK%2F0qVrCmj2j3NiMricQjOPWOkAEXekIPA%3D'\n",
    "        account_name = 'willbedeletedsoon'\n",
    "        container_name = 'codx-pede-s02'\n",
    "        #blob_name = 'cost-of-living_v2_I0869'\n",
    "        def get_data_from_blob(sas_token, account_name, container_name, blob_name):\n",
    "            block_blob_service = BlockBlobService(account_name=account_name, sas_token= sas_token)\n",
    "            from_blob = block_blob_service.get_blob_to_text(container_name = container_name, blob_name=blob_name)\n",
    "            return pd.read_csv(StringIO(from_blob.content))\n",
    "        input_df=get_data_from_blob(sas_token, account_name, container_name, blob_name)\n",
    "        #filtering out empty columns\n",
    "        input_df = input_df[input_df.x2.notnull()]\n",
    "        input_df = input_df[input_df.x23.notnull()]\n",
    "        input_df = input_df[input_df.x33.notnull()]\n",
    "        input_df = input_df[input_df.x54.notnull()]\n",
    "        data_good = input_df[input_df[\"data_quality\"] == 1]\n",
    "        \n",
    "        ##print(data_good)\n",
    "        return(input_df)\n",
    "    except Exception as error_msg:\n",
    "        logger.info(f\"Exception occured while reading the dataset: {blob_name}\"\n",
    "                    f\"Error Info is  {error_msg}\")\n",
    "\n",
    "\n",
    "def getGraph(dframe, filters):\n",
    "    logger.info(\n",
    "        \"Preparing bar graph json to understand basic_expenditure across all countries\")\n",
    "    column_names = ['x48', 'x38', 'x37', 'x36', 'x33', 'x8', 'x29']\n",
    "    #print(dframe['country'])\n",
    "    data_good = dframe[dframe[\"data_quality\"] == 1]\n",
    "    data_good['basic_expenditure']= data_good[column_names].sum(axis=1)\n",
    "    for item in filters:\n",
    "        if 'All' in filters[item]:\n",
    "            continue\n",
    "        elif isinstance(filters[item], list):\n",
    "            data_good = data_good[data_good[item].isin(filters[item])]\n",
    "        else:\n",
    "            data_good = data_good[data_good[item] == filters[item]]\n",
    "    fig = px.bar(data_good, x='x48', y='country', color='basic_expenditure')\n",
    "    #fig.show()\n",
    "    logger.info(\n",
    "        \"Successfully prepared bar graph json to understand basic_expenditure across all countries\")\n",
    "    return io.to_json(fig)\n",
    "\n",
    "\n",
    "selected_filters = {\"country\": ['India','China','Russia']}\n",
    "dframe = fiile_read(\"cost-of-living_v2_I0869.csv\")\n",
    "#dframe = dframe.groupby(['country'])\n",
    "dynamic_outputs = getGraph(dframe, selected_filters)#here11\n",
    "\n",
    "\"\"\"\n",
    "# #END CUSTOM CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_2_Filters = \"\"\"\n",
    "## Below codestring is used to create filters to show different regions data in  product historic screen.\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from io import StringIO\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "def getLogger():\n",
    "    import logging\n",
    "    logging.basicConfig(filename=\"UIACLogger.log\",\n",
    "                        format='%(asctime)s %(message)s',\n",
    "                        filemode='a')\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    return logger\n",
    "\n",
    "\n",
    "logger = getLogger()\n",
    "\n",
    "\n",
    "def fiile_read(blob_name):\n",
    "    #reading the file from azure blob storage container\n",
    "    logger.info(f\"Read dataset file: {blob_name}\")\n",
    "    try:\n",
    "        from azure.storage.blob import BlockBlobService\n",
    "        sas_token = '?sv=2021-04-10&st=2022-12-22T08%3A12%3A47Z&se=2023-12-30T08%3A12%3A00Z&sr=c&sp=racwl&sig=fMeYkXsCvwK%2F0qVrCmj2j3NiMricQjOPWOkAEXekIPA%3D'\n",
    "        account_name = 'willbedeletedsoon'\n",
    "        container_name = 'codx-pede-s02'\n",
    "        #blob_name = 'cost-of-living_v2_I0869'\n",
    "        def get_data_from_blob(sas_token, account_name, container_name, blob_name):\n",
    "            block_blob_service = BlockBlobService(account_name=account_name, sas_token= sas_token)\n",
    "            from_blob = block_blob_service.get_blob_to_text(container_name = container_name, blob_name=blob_name)\n",
    "            return pd.read_csv(StringIO(from_blob.content))\n",
    "        input_df=get_data_from_blob(sas_token, account_name, container_name, blob_name)\n",
    "        #filtering out empty columns\n",
    "        input_df = input_df[input_df.x2.notnull()]\n",
    "        input_df = input_df[input_df.x23.notnull()]\n",
    "        input_df = input_df[input_df.x33.notnull()]\n",
    "        input_df = input_df[input_df.x54.notnull()]\n",
    "        data_good = input_df[input_df[\"data_quality\"] == 1]\n",
    "        \n",
    "        ##print(data_good)\n",
    "        return(data_good)\n",
    "    except Exception as error_msg:\n",
    "        logger.info(f\"Exception occured while reading the dataset: {blob_name}\"\n",
    "                    f\"Error Info is  {error_msg}\")\n",
    "\n",
    "\n",
    "def get_response_filters(current_filter_params, df, default_values_selected, all_filters, multi_select_filters, extra_filters={}):\n",
    "    logger.info(\"Preparing filter dictionary\")\n",
    "    # Usage\n",
    "    # -----\n",
    "    # >>> filter_df = pd.DataFrame(columns=[....])    # Optional operation\n",
    "    # >>> filter_df = final_ADS.groupby(......)       # Optional operation\n",
    "    # >>> default_values_selected = {}    # The default value to be selected for a filter, provide filter_name, filter_values\n",
    "    # >>> all_option_filters = []         # Filters with an All option\n",
    "    # >>> multi_select_filters = []       # Filters with an multi_select option\n",
    "    # >>> more_filters = {}               # Extra filters, provide filter_names, filter_options\n",
    "    # >>> final_dict_out = get_response_filters(current_filter_params, filter_df, default_values_selected, all_option_filters, multi_select_filters, more_filters)\n",
    "    # >>> dynamic_outputs = json.dumps(final_dict_out)\n",
    "    # Returns\n",
    "    # -------\n",
    "    # A dict object containing the filters JSON structure\n",
    "\n",
    "    filters = list(df.columns)\n",
    "    default_values_possible = {}\n",
    "    for item in filters:\n",
    "        default_possible = list(df[item].unique())\n",
    "        if item in all_filters:\n",
    "            default_possible = list(chain(['All'], default_possible))\n",
    "        default_values_possible[item] = default_possible\n",
    "    if extra_filters:\n",
    "        filters.extend(list(extra_filters.keys()))\n",
    "        default_values_possible.update(extra_filters)\n",
    "    if current_filter_params:\n",
    "        selected_filters = current_filter_params[\"selected\"]\n",
    "        # current_filter = current_filter_params[\"current_filter\"]\n",
    "        # current_index = filters.index(current_filter)\n",
    "        select_df = df.copy()\n",
    "    final_dict = {}\n",
    "    iter_value = 0\n",
    "    data_values = []\n",
    "    default_values = {}\n",
    "    for item in filters:\n",
    "        filter_dict = {}\n",
    "        filter_dict[\"widget_filter_index\"] = int(iter_value)\n",
    "        filter_dict[\"widget_filter_function\"] = False\n",
    "        filter_dict[\"widget_filter_function_parameter\"] = False\n",
    "        filter_dict[\"widget_filter_hierarchy_key\"] = False\n",
    "        filter_dict[\"widget_filter_isall\"] = True if item in all_filters else False\n",
    "        filter_dict[\"widget_filter_multiselect\"] = True if item in multi_select_filters else False\n",
    "        filter_dict[\"widget_tag_key\"] = str(item)\n",
    "        filter_dict[\"widget_tag_label\"] = str(item)\n",
    "        filter_dict[\"widget_tag_input_type\"] = \"select\",\n",
    "        filter_dict[\"widget_filter_dynamic\"] = True\n",
    "        if current_filter_params:\n",
    "            if item in df.columns:\n",
    "                possible_values = list(select_df[item].unique())\n",
    "                item_default_value = selected_filters[item]\n",
    "                if item in all_filters:\n",
    "                    possible_values = list(chain(['All'], possible_values))\n",
    "                if item in multi_select_filters:\n",
    "                    for value in selected_filters[item]:\n",
    "                        if value not in possible_values:\n",
    "                            if possible_values[0] == \"All\":\n",
    "                                item_default_value = possible_values\n",
    "                            else:\n",
    "                                item_default_value = [possible_values[0]]\n",
    "                else:\n",
    "                    if selected_filters[item] not in possible_values:\n",
    "                        item_default_value = possible_values[0]\n",
    "                filter_dict[\"widget_tag_value\"] = possible_values\n",
    "                if item in multi_select_filters:\n",
    "                    if 'All' not in item_default_value and selected_filters[item]:\n",
    "                        select_df = select_df[select_df[item].isin(\n",
    "                            item_default_value)]\n",
    "                else:\n",
    "                    if selected_filters[item] != 'All':\n",
    "                        select_df = select_df[select_df[item]\n",
    "                                              == item_default_value]\n",
    "            else:\n",
    "                filter_dict[\"widget_tag_value\"] = extra_filters[item]\n",
    "        else:\n",
    "            filter_dict[\"widget_tag_value\"] = default_values_possible[item]\n",
    "            item_default_value = default_values_selected[item]\n",
    "        data_values.append(filter_dict)\n",
    "        default_values[item] = item_default_value\n",
    "        iter_value = iter_value + 1\n",
    "    final_dict[\"dataValues\"] = data_values\n",
    "    final_dict[\"defaultValues\"] = default_values\n",
    "    logger.info(\"Successfully prepared filter dictionary\")\n",
    "    return final_dict\n",
    "\n",
    "\n",
    "def prepare_filter_json():\n",
    "    logger.info(f\"Preparing json for Filters in Historical Screen\")\n",
    "    # Preapre Filter json for Region in the Historical View Screen.\n",
    "    dframe = fiile_read(\"cost-of-living_v2_I0869\")\n",
    "    default_values_selected = {\"country\": 'India'}\n",
    "    all_filters = []\n",
    "    multi_select_filters = []\n",
    "    current_filter_params = {\"selected\": default_values_selected}\n",
    "    final_dict_out = get_response_filters(\n",
    "        current_filter_params, dframe, default_values_selected, all_filters, multi_select_filters)\n",
    "    logger.info(f\"Successful prepared json for Filters in Historical Screen\")\n",
    "    return json.dumps(final_dict_out)\n",
    "\n",
    "\n",
    "dynamic_outputs = prepare_filter_json()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_2_Table = \"\"\"\n",
    "# Below codestring is used to display the grid table that consists of historic sales done over time on each product.\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "def getLogger():\n",
    "    import logging\n",
    "    logging.basicConfig(filename=\"UIACLogger.log\",\n",
    "                        format='%(asctime)s %(message)s',\n",
    "                        filemode='a')\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    return logger\n",
    "\n",
    "\n",
    "logger = getLogger()\n",
    "\n",
    "\n",
    "def file_read(blob_name):\n",
    "    #reading the file from azure blob storage container\n",
    "    logger.info(f\"Read dataset file: {blob_name}\")\n",
    "    try:\n",
    "        from azure.storage.blob import BlockBlobService\n",
    "        sas_token = '?sv=2021-04-10&st=2022-12-22T08%3A12%3A47Z&se=2023-12-30T08%3A12%3A00Z&sr=c&sp=racwl&sig=fMeYkXsCvwK%2F0qVrCmj2j3NiMricQjOPWOkAEXekIPA%3D'\n",
    "        account_name = 'willbedeletedsoon'\n",
    "        container_name = 'codx-pede-s02'\n",
    "        #blob_name = 'cost-of-living_v2_I0869'\n",
    "        def get_data_from_blob(sas_token, account_name, container_name, blob_name):\n",
    "            block_blob_service = BlockBlobService(account_name=account_name, sas_token= sas_token)\n",
    "            from_blob = block_blob_service.get_blob_to_text(container_name = container_name, blob_name=blob_name)\n",
    "            return pd.read_csv(StringIO(from_blob.content))\n",
    "        input_df=get_data_from_blob(sas_token, account_name, container_name, blob_name)\n",
    "        #filtering out empty columns\n",
    "        # input_df = input_df[input_df.x2.notnull()]\n",
    "        # input_df = input_df[input_df.x23.notnull()]\n",
    "        # input_df = input_df[input_df.x33.notnull()]\n",
    "        # input_df = input_df[input_df.x54.notnull()]\n",
    "        data_good = input_df[input_df[\"data_quality\"] == 1]\n",
    "        \n",
    "        ##print(data_good)\n",
    "        return(data_good)\n",
    "    except Exception as error_msg:\n",
    "        logger.info(f\"Exception occured while reading the dataset: {blob_name}\"\n",
    "                    f\"Error Info is  {error_msg}\")\n",
    "\n",
    "\n",
    "def get_filter_table(dframe, selected_filters):\n",
    "    logger.info(\"Applying screen filters on the grid table dframe.\")\n",
    "    select_df = dframe.copy()\n",
    "    for item in list(selected_filters):\n",
    "        if isinstance(selected_filters[item], list):\n",
    "            if 'All' not in selected_filters[item] and selected_filters[item]:\n",
    "                select_df = select_df[select_df[item].isin(\n",
    "                    selected_filters[item])]\n",
    "        else:\n",
    "            if selected_filters[item] != 'All':\n",
    "                select_df = select_df[select_df[item]\n",
    "                                      == selected_filters[item]]\n",
    "    logger.info(\"Successfully applied screen filters on the grid table dframe.\")\n",
    "    return select_df\n",
    "\n",
    "\n",
    "def generate_dynamic_table(dframe, name='Sales', grid_options={\"tableSize\": \"small\", \"tableMaxHeight\": \"80vh\", \"quickSearch\":True}, group_headers=[], grid=\"auto\"):\n",
    "    logger.info(\"Generate dynamic Grid table json from dframe\")\n",
    "    table_dict = {}\n",
    "    table_props = {}\n",
    "    table_dict.update({\"grid\": grid, \"type\": \"tabularForm\",\n",
    "                      \"noGutterBottom\": True, 'name': name})\n",
    "    values_dict = dframe.dropna(axis=1).to_dict(\"records\")\n",
    "    table_dict.update({\"value\": values_dict})\n",
    "    col_def_list = []\n",
    "    for col in list(dframe.columns):\n",
    "        col_def_dict = {}\n",
    "        col_def_dict.update({\"headerName\": col, \"field\": col})\n",
    "        col_def_list.append(col_def_dict)\n",
    "    table_props[\"groupHeaders\"] = group_headers\n",
    "    table_props[\"coldef\"] = col_def_list\n",
    "    table_props[\"gridOptions\"] = grid_options\n",
    "    table_dict.update({\"tableprops\": table_props})\n",
    "    logger.info(\"Successfully generated dynamic Grid table json from dframe\")\n",
    "    return table_dict\n",
    "\n",
    "\n",
    "def build_grid_table_json():\n",
    "    logger.info(\"Preparing grid table json for Historical Screen\")\n",
    "    form_config = {}\n",
    "    dframe = file_read(\"cost-of-living_v2_I0869.csv\")\n",
    "\n",
    "    dframe=dframe[['country','city','x48', 'x37', 'x36', 'x8','x30']]\n",
    "    dframe.columns = dframe.columns.str.replace('x48', 'Apartment')\n",
    "    dframe.columns = dframe.columns.str.replace('x37', 'Mobile Tariff')\n",
    "    dframe.columns = dframe.columns.str.replace('x36', 'Basic cost')\n",
    "    dframe.columns = dframe.columns.str.replace('x8', 'Water')\n",
    "    dframe.columns = dframe.columns.str.replace('x30', 'Taxi')\n",
    "    #dframe=dframe.sample(n = 50)\n",
    "    #print(dframe)\n",
    "    \n",
    "    selected_filters = {\"country\": ['India','China','Russia','United States']}\n",
    "\n",
    "    dframe2 = get_filter_table(dframe, selected_filters)\n",
    "    dframe2=dframe2.sample(n = 50)\n",
    "    print(dframe2)\n",
    "    form_config['fields'] = [generate_dynamic_table(dframe2)]\n",
    "    grid_table_json = {}\n",
    "    grid_table_json['form_config'] = form_config\n",
    "    logger.info(\"Successfully prepared grid table json for Historical Screen\")\n",
    "    print(grid_table_json)\n",
    "    return grid_table_json\n",
    "\n",
    "\n",
    "grid_table_json = build_grid_table_json()\n",
    "dynamic_outputs = json.dumps(grid_table_json)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_3_Table = \"\"\"\n",
    "# Below codestring is used to display the grid table that consists of historic sales done over time on each product.\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "def getLogger():\n",
    "    import logging\n",
    "    logging.basicConfig(filename=\"UIACLogger.log\",\n",
    "                        format='%(asctime)s %(message)s',\n",
    "                        filemode='a')\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    return logger\n",
    "\n",
    "\n",
    "logger = getLogger()\n",
    "\n",
    "\n",
    "def file_read(blob_name):\n",
    "    #reading the file from azure blob storage container\n",
    "    logger.info(f\"Read dataset file: {blob_name}\")\n",
    "    try:\n",
    "        from azure.storage.blob import BlockBlobService\n",
    "        sas_token = '?sv=2021-04-10&st=2022-12-22T08%3A12%3A47Z&se=2023-12-30T08%3A12%3A00Z&sr=c&sp=racwl&sig=fMeYkXsCvwK%2F0qVrCmj2j3NiMricQjOPWOkAEXekIPA%3D'\n",
    "        account_name = 'willbedeletedsoon'\n",
    "        container_name = 'codx-pede-s02'\n",
    "        #blob_name = 'cost-of-living_v2_I0869' fiile_read(\"cost-of-living_v2_I0869\")\n",
    "        def get_data_from_blob(sas_token, account_name, container_name, blob_name):\n",
    "            block_blob_service = BlockBlobService(account_name=account_name, sas_token= sas_token)\n",
    "            from_blob = block_blob_service.get_blob_to_text(container_name = container_name, blob_name=blob_name)\n",
    "            return pd.read_csv(StringIO(from_blob.content))\n",
    "        input_df=get_data_from_blob(sas_token, account_name, container_name, blob_name)\n",
    "        #filtering out empty columns\n",
    "        input_df = input_df[input_df.x2.notnull()]\n",
    "        input_df = input_df[input_df.x8.notnull()]\n",
    "        input_df = input_df[input_df.x33.notnull()]\n",
    "        input_df = input_df[input_df.x54.notnull()]\n",
    "        input_df = input_df[input_df.x48.notnull()]\n",
    "        input_df = input_df[input_df.x37.notnull()]\n",
    "        input_df = input_df[input_df.x36.notnull()]\n",
    "        data_good = input_df[input_df[\"data_quality\"] == 1]\n",
    "        \n",
    "        #print(data_good)\n",
    "        return(data_good)\n",
    "    except Exception as error_msg:\n",
    "        logger.info(f\"Exception occured while reading the dataset: {blob_name}\"\n",
    "                    f\"Error Info is  {error_msg}\")\n",
    "\n",
    "\n",
    "def get_filter_table(dframe, selected_filters):\n",
    "    logger.info(\"Applying screen filters on the grid table dframe.\")\n",
    "    select_df = dframe.copy()\n",
    "    for item in list(selected_filters):\n",
    "        if isinstance(selected_filters[item], list):\n",
    "            if 'All' not in selected_filters[item] and selected_filters[item]:\n",
    "                select_df = select_df[select_df[item].isin(\n",
    "                    selected_filters[item])]\n",
    "        else:\n",
    "            if selected_filters[item] != 'All':\n",
    "                select_df = select_df[select_df[item]\n",
    "                                      == selected_filters[item]]\n",
    "    logger.info(\"Successfully applied screen filters on the grid table dframe.\")\n",
    "    return select_df\n",
    "\n",
    "\n",
    "def generate_dynamic_table(dframe, name='Sales', grid_options={\"tableSize\": \"small\", \"tableMaxHeight\": \"80vh\", \"quickSearch\":True}, group_headers=[], grid=\"auto\"):\n",
    "    logger.info(\"Generate dynamic Grid table json from dframe\")\n",
    "    table_dict = {}\n",
    "    table_props = {}\n",
    "    table_dict.update({\"grid\": grid, \"type\": \"tabularForm\",\n",
    "                      \"noGutterBottom\": True, 'name': name})\n",
    "    values_dict = dframe.dropna(axis=1).to_dict(\"records\")\n",
    "    table_dict.update({\"value\": values_dict})\n",
    "    col_def_list = []\n",
    "    for col in list(dframe.columns):\n",
    "        col_def_dict = {}\n",
    "        col_def_dict.update({\"headerName\": col, \"field\": col})\n",
    "        col_def_list.append(col_def_dict)\n",
    "    table_props[\"groupHeaders\"] = group_headers\n",
    "    table_props[\"coldef\"] = col_def_list\n",
    "    table_props[\"gridOptions\"] = grid_options\n",
    "    table_dict.update({\"tableprops\": table_props})\n",
    "    logger.info(\"Successfully generated dynamic Grid table json from dframe\")\n",
    "    return table_dict\n",
    "\n",
    "\n",
    "def build_grid_table_json():\n",
    "    logger.info(\"Preparing grid table json for Colour Screen\")\n",
    "    form_config = {}\n",
    "    dframe = file_read(\"cost-of-living_v2_I0869.csv\")\n",
    "    dframe=dframe[['country','x48', 'x37', 'x36', 'x8']] #--here281222 --5 columns\n",
    "    dframe.columns = dframe.columns.str.replace('x48', 'Apartment')\n",
    "    dframe.columns = dframe.columns.str.replace('x37', 'Mobile Tariff')\n",
    "    dframe.columns = dframe.columns.str.replace('x36', 'Basic cost')\n",
    "    dframe.columns = dframe.columns.str.replace('x8', 'Water')\n",
    "    \n",
    "    selected_filters = {\"country\": 'India'}\n",
    "    \n",
    "    dframe2 = get_filter_table(dframe, selected_filters)\n",
    "    form_config['fields'] = [generate_dynamic_table(dframe2)]\n",
    "    grid_table_json = {}\n",
    "    grid_table_json['form_config'] = form_config\n",
    "    logger.info(\"Successfully prepared grid table json for Colour Screen\")\n",
    "    return grid_table_json\n",
    "\n",
    "\n",
    "grid_table_json = build_grid_table_json()\n",
    "dynamic_outputs = json.dumps(grid_table_json)\n",
    "\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_4 = \"\"\"\n",
    "# Below codestring is used to perform detailed analysis on quantity of sales done over time. \n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import json\n",
    "from io import StringIO\n",
    "import plotly.io as io\n",
    "\n",
    "\n",
    "def getLogger():\n",
    "    import logging\n",
    "    logging.basicConfig(filename=\"UIACLogger.log\",\n",
    "                        format='%(asctime)s %(message)s',\n",
    "                        filemode='a')\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    return logger\n",
    "\n",
    "\n",
    "logger = getLogger()\n",
    "\n",
    "\n",
    "def fiile_read(blob_name):\n",
    "    #reading the file from azure blob storage container\n",
    "    logger.info(f\"Read dataset file: {blob_name}\")\n",
    "    try:\n",
    "        from azure.storage.blob import BlockBlobService\n",
    "        sas_token = '?sv=2021-04-10&st=2022-12-22T08%3A12%3A47Z&se=2023-12-30T08%3A12%3A00Z&sr=c&sp=racwl&sig=fMeYkXsCvwK%2F0qVrCmj2j3NiMricQjOPWOkAEXekIPA%3D'\n",
    "        account_name = 'willbedeletedsoon'\n",
    "        container_name = 'codx-pede-s02'\n",
    "        #blob_name = 'cost-of-living_v2_I0869'\n",
    "        def get_data_from_blob(sas_token, account_name, container_name, blob_name):\n",
    "            block_blob_service = BlockBlobService(account_name=account_name, sas_token= sas_token)\n",
    "            from_blob = block_blob_service.get_blob_to_text(container_name = container_name, blob_name=blob_name)\n",
    "            return pd.read_csv(StringIO(from_blob.content))\n",
    "        input_df=get_data_from_blob(sas_token, account_name, container_name, blob_name)\n",
    "        #filtering out empty columns\n",
    "        input_df = input_df[input_df.x2.notnull()]\n",
    "        input_df = input_df[input_df.x23.notnull()]\n",
    "        input_df = input_df[input_df.x33.notnull()]\n",
    "        input_df = input_df[input_df.x54.notnull()]\n",
    "        data_good = input_df[input_df[\"data_quality\"] == 1]\n",
    "        \n",
    "        ##print(data_good)\n",
    "        return(input_df)\n",
    "    except Exception as error_msg:\n",
    "        logger.info(f\"Exception occured while reading the dataset: {blob_name}\"\n",
    "                    f\"Error Info is  {error_msg}\")\n",
    "\n",
    "\n",
    "def getGraph(dframe, filters):\n",
    "    logger.info(\n",
    "        \"Preparing bar graph json to understand basic_expenditure across all countries\")\n",
    "    column_names = ['x48', 'x38', 'x37', 'x36', 'x33', 'x8', 'x29']\n",
    "    #print(dframe['country'])\n",
    "    data_good = dframe[dframe[\"data_quality\"] == 1]\n",
    "    data_good['basic_expenditure']= data_good[column_names].sum(axis=1)\n",
    "    for item in filters:\n",
    "        if 'All' in filters[item]:\n",
    "            continue\n",
    "        elif isinstance(filters[item], list):\n",
    "            data_good = data_good[data_good[item].isin(filters[item])]\n",
    "        else:\n",
    "            data_good = data_good[data_good[item] == filters[item]]\n",
    "    fig = px.bar(data_good, x='basic_expenditure', y='country') #, color='city'\n",
    "    #fig = px.scatter(data_good, y='basic_expenditure', x='country')\n",
    "    #print(data_good[['basic_expenditure','country']].where(data_good['country'] == 'Denmark')) #--here3\n",
    "    #data_good1 = data_good[data_good['country'] == 'Denmark']\n",
    "    #print(data_good1)\n",
    "    fig.show()\n",
    "    logger.info(\n",
    "        \"Successfully prepared bar graph json to understand basic_expenditure across all countries\")\n",
    "    return io.to_json(fig)\n",
    "\n",
    "\n",
    "selected_filters = {\"country\": ['India','United States']}\n",
    "dframe = fiile_read(\"cost-of-living_v2_I0869.csv\")\n",
    "#dframe = dframe.groupby(['country'])\n",
    "dynamic_outputs = getGraph(dframe, selected_filters)#here11\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_4_a =\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import json\n",
    "from io import StringIO\n",
    "import plotly.io as io\n",
    "from plotly.io import to_json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getLogger():\n",
    "    import logging\n",
    "    logging.basicConfig(filename=\"UIACLogger.log\",\n",
    "                        format='%(asctime)s %(message)s',\n",
    "                        filemode='a')\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    return logger\n",
    "\n",
    "\n",
    "logger = getLogger()\n",
    "\n",
    "\n",
    "\n",
    "def getGraph():\n",
    "    logger.info(\n",
    "        \"Preparing scatter plot json to understand relation between x and y values\")\n",
    "    df = pd.DataFrame(np.random.randint(0,100,size=(100, 1)), columns=list('X'))\n",
    "    df = df.assign(Y = lambda x: (x['X']**2))\n",
    "    fig = px.scatter(df, y='Y', x='X')\n",
    "    fig.show()\n",
    "    return io.to_json(fig)\n",
    "dynamic_outputs = getGraph()\n",
    "#print(df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_5 =\"\"\"\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import json\n",
    "from io import StringIO\n",
    "import plotly.io as io\n",
    "from plotly.io import to_json\n",
    "\n",
    "\n",
    "\n",
    "def getLogger():\n",
    "    import logging\n",
    "    logging.basicConfig(filename=\"UIACLogger.log\",\n",
    "                        format='%(asctime)s %(message)s',\n",
    "                        filemode='a')\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    return logger\n",
    "\n",
    "\n",
    "logger = getLogger()\n",
    "\n",
    "def fiile_read(blob_name):\n",
    "    #reading the file from azure blob storage container\n",
    "    logger.info(f\"Read dataset file: {blob_name}\")\n",
    "    try:\n",
    "        from azure.storage.blob import BlockBlobService\n",
    "        sas_token = '?sv=2021-04-10&st=2022-12-22T08%3A12%3A47Z&se=2023-12-30T08%3A12%3A00Z&sr=c&sp=racwl&sig=fMeYkXsCvwK%2F0qVrCmj2j3NiMricQjOPWOkAEXekIPA%3D'\n",
    "        account_name = 'willbedeletedsoon'\n",
    "        container_name = 'codx-pede-s02'\n",
    "        #blob_name = 'cost-of-living_v2_I0869'\n",
    "        def get_data_from_blob(sas_token, account_name, container_name, blob_name):\n",
    "            block_blob_service = BlockBlobService(account_name=account_name, sas_token= sas_token)\n",
    "            from_blob = block_blob_service.get_blob_to_text(container_name = container_name, blob_name=blob_name)\n",
    "            return pd.read_csv(StringIO(from_blob.content))\n",
    "        input_df=get_data_from_blob(sas_token, account_name, container_name, blob_name)\n",
    "        #filtering out empty columns\n",
    "        input_df = input_df[input_df.x2.notnull()]\n",
    "        input_df = input_df[input_df.x23.notnull()]\n",
    "        input_df = input_df[input_df.x33.notnull()]\n",
    "        input_df = input_df[input_df.x54.notnull()]\n",
    "        data_good = input_df[input_df[\"data_quality\"] == 1]\n",
    "        \n",
    "        ##print(data_good)\n",
    "        return(input_df)\n",
    "    except Exception as error_msg:\n",
    "        logger.info(f\"Exception occured while reading the dataset: {blob_name}\"\n",
    "                    f\"Error Info is  {error_msg}\")\n",
    "\n",
    "def getGraph():\n",
    "    logger.info(\n",
    "        \"Preparing scatter plot json to understand relation between x and y values\")\n",
    "    # load dataset\n",
    "    #df = pd.DataFrame(np.random.randint(0,100,size=(100, 2)), columns=list('XY'))\n",
    "    #df = df.assign(Y = lambda x: (x['X']**2))\n",
    "    #df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/volcano.csv\")\n",
    "    input_df=fiile_read(\"cost-of-living_v2_I0869.csv\")\n",
    "        #filtering out empty columns\n",
    "    df = input_df[input_df[\"data_quality\"] == 1].groupby(['city'])\n",
    "    df = input_df[input_df[\"country\"] == 'India']\n",
    "    #print(df)\n",
    "    # create figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add surface trace\n",
    "    fig.add_trace(go.Surface(  x=df.city,y=df.x54, colorscale=\"Viridis\"))\n",
    "\n",
    "    # Update plot sizing\n",
    "    # fig.update_layout(\n",
    "    #     width=800,\n",
    "    #     height=900,\n",
    "    #     autosize=False,\n",
    "    #     margin=dict(t=0, b=0, l=0, r=0),\n",
    "    #     template=\"plotly_white\",\n",
    "    # )\n",
    "\n",
    "    # Update 3D scene options\n",
    "    # fig.update_scenes(\n",
    "    #     aspectratio=dict(x=1, y=1, z=0.7),\n",
    "    #     aspectmode=\"manual\"\n",
    "    # )\n",
    "\n",
    "    # Add dropdown\n",
    "    fig.update_layout(\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                buttons=list([\n",
    "                    dict(\n",
    "                        args=[\"type\", \"bar\"],\n",
    "                        label=\"bar\",\n",
    "                        method=\"restyle\"\n",
    "                    ),\n",
    "                    dict(\n",
    "                        args=[\"type\", \"scatter\"],\n",
    "                        label=\"scatter\",\n",
    "                        method=\"restyle\"\n",
    "                    ),\n",
    "                    dict(\n",
    "                        args=[\"type\", \"violin\"],\n",
    "                        label=\"violin\",\n",
    "                        method=\"restyle\"\n",
    "                    ),\n",
    "                    dict(\n",
    "                        args=[\"type\", \"column\"],\n",
    "                        label=\"column\",\n",
    "                        method=\"restyle\"\n",
    "                    ),\n",
    "                    dict(\n",
    "                        args=[\"type\", \"box\"],\n",
    "                        label=\"box\",\n",
    "                        method=\"restyle\"\n",
    "                    )\n",
    "                ]),\n",
    "                direction=\"down\",\n",
    "                pad={\"r\": 10, \"t\": 10},\n",
    "                showactive=True,\n",
    "                x=0.1,\n",
    "                xanchor=\"left\",\n",
    "                y=1.1,\n",
    "                yanchor=\"top\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Add annotation\n",
    "    fig.update_layout(\n",
    "        annotations=[\n",
    "            dict(text=\"Trace type:\", showarrow=False,\n",
    "            x=0, y=1.085, yref=\"paper\", align=\"left\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    return io.to_json(fig)\n",
    "\n",
    "dynamic_outputs = getGraph()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters={\n",
    "    \"step_2_Filters\" : step_2_Filters\n",
    "}\n",
    "plots_dict={\n",
    "    \"step_2_Table\":step_2_Table,\n",
    "    \"step_3_Table\":step_3_Table,\n",
    "    \"step_1\":step_1,\n",
    "    \"step_4_a\":step_4_a,\n",
    "    \"step_5\":step_5\n",
    "}\n",
    "results_json.append({\n",
    "    'type':'review',\n",
    "    'name': 'overview',\n",
    "    'component':'overview',\n",
    "    'dynamic_visual_results': plots_dict,  \n",
    "    'dynamic_code_filters' : filters    \n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2) {}\n",
      "{'$schema': 'http://json-schema.org/draft-04/schema#', 'description': 'Jupyter Notebook v4.2 JSON schema.', 'type': 'object', 'additionalProperties': False, 'required': ['metadata', 'nbformat_minor', 'nbformat', 'cells'], 'properties': {'metadata': {'description': 'Notebook root-level metadata.', 'type': 'object', 'additionalProperties': True, 'properties': {'kernelspec': {'description': 'Kernel information.', 'type': 'object', 'required': ['name', 'display_name'], 'properties': {'name': {'description': 'Name of the kernel specification.', 'type': 'string'}, 'display_name': {'description': 'Name to display in UI.', 'type': 'string'}}}, 'language_info': {'description': 'Kernel information.', 'type': 'object', 'required': ['name'], 'properties': {'name': {'description': 'The programming language which this kernel runs.', 'type': 'string'}, 'codemirror_mode': {'description': 'The codemirror mode to use for code in this language.', 'oneOf': [{'type': 'string'}, {'type': 'object'}]}, 'file_extension': {'description': 'The file extension for files in this language.', 'type': 'string'}, 'mimetype': {'description': 'The mimetype corresponding to files in this language.', 'type': 'string'}, 'pygments_lexer': {'description': 'The pygments lexer to use for code in this language.', 'type': 'string'}}}, 'orig_nbformat': {'description': 'Original notebook format (major number) before converting the notebook between versions. This should never be written to a file.', 'type': 'integer', 'minimum': 1}, 'title': {'description': 'The title of the notebook document', 'type': 'string'}, 'authors': {'description': 'The author(s) of the notebook document', 'type': 'array', 'item': {'type': 'object', 'properties': {'name': {'type': 'string'}}, 'additionalProperties': True}}}}, 'nbformat_minor': {'description': 'Notebook format (minor number). Incremented for backward compatible changes to the notebook format.', 'type': 'integer', 'minimum': 2}, 'nbformat': {'description': 'Notebook format (major number). Incremented between backwards incompatible changes to the notebook format.', 'type': 'integer', 'minimum': 4, 'maximum': 4}, 'cells': {'description': 'Array of cells of the current notebook.', 'type': 'array', 'items': {'$ref': '#/definitions/cell'}}}, 'definitions': {'cell': {'type': 'object', 'oneOf': [{'$ref': '#/definitions/raw_cell'}, {'$ref': '#/definitions/markdown_cell'}, {'$ref': '#/definitions/code_cell'}]}, 'raw_cell': {'description': 'Notebook raw nbconvert cell.', 'type': 'object', 'additionalProperties': False, 'required': ['cell_type', 'metadata', 'source'], 'properties': {'cell_type': {'description': 'String identifying the type of cell.', 'enum': ['raw']}, 'metadata': {'description': 'Cell-level metadata.', 'type': 'object', 'additionalProperties': True, 'properties': {'format': {'description': 'Raw cell metadata format for nbconvert.', 'type': 'string'}, 'name': {'$ref': '#/definitions/misc/metadata_name'}, 'tags': {'$ref': '#/definitions/misc/metadata_tags'}}}, 'attachments': {'$ref': '#/definitions/misc/attachments'}, 'source': {'$ref': '#/definitions/misc/source'}}}, 'markdown_cell': {'description': 'Notebook markdown cell.', 'type': 'object', 'additionalProperties': False, 'required': ['cell_type', 'metadata', 'source'], 'properties': {'cell_type': {'description': 'String identifying the type of cell.', 'enum': ['markdown']}, 'metadata': {'description': 'Cell-level metadata.', 'type': 'object', 'properties': {'name': {'$ref': '#/definitions/misc/metadata_name'}, 'tags': {'$ref': '#/definitions/misc/metadata_tags'}}, 'additionalProperties': True}, 'attachments': {'$ref': '#/definitions/misc/attachments'}, 'source': {'$ref': '#/definitions/misc/source'}}}, 'code_cell': {'description': 'Notebook code cell.', 'type': 'object', 'additionalProperties': False, 'required': ['cell_type', 'metadata', 'source', 'outputs', 'execution_count'], 'properties': {'cell_type': {'description': 'String identifying the type of cell.', 'enum': ['code']}, 'metadata': {'description': 'Cell-level metadata.', 'type': 'object', 'additionalProperties': True, 'properties': {'collapsed': {'description': 'Whether the cell is collapsed/expanded.', 'type': 'boolean'}, 'scrolled': {'description': \"Whether the cell's output is scrolled, unscrolled, or autoscrolled.\", 'enum': [True, False, 'auto']}, 'name': {'$ref': '#/definitions/misc/metadata_name'}, 'tags': {'$ref': '#/definitions/misc/metadata_tags'}}}, 'source': {'$ref': '#/definitions/misc/source'}, 'outputs': {'description': 'Execution, display, or stream outputs.', 'type': 'array', 'items': {'$ref': '#/definitions/output'}}, 'execution_count': {'description': \"The code cell's prompt number. Will be null if the cell has not been run.\", 'type': ['integer', 'null'], 'minimum': 0}}}, 'unrecognized_cell': {'description': 'Unrecognized cell from a future minor-revision to the notebook format.', 'type': 'object', 'additionalProperties': True, 'required': ['cell_type', 'metadata'], 'properties': {'cell_type': {'description': 'String identifying the type of cell.', 'not': {'enum': ['markdown', 'code', 'raw']}}, 'metadata': {'description': 'Cell-level metadata.', 'type': 'object', 'properties': {'name': {'$ref': '#/definitions/misc/metadata_name'}, 'tags': {'$ref': '#/definitions/misc/metadata_tags'}}, 'additionalProperties': True}}}, 'output': {'type': 'object', 'oneOf': [{'$ref': '#/definitions/execute_result'}, {'$ref': '#/definitions/display_data'}, {'$ref': '#/definitions/stream'}, {'$ref': '#/definitions/error'}]}, 'execute_result': {'description': 'Result of executing a code cell.', 'type': 'object', 'additionalProperties': False, 'required': ['output_type', 'data', 'metadata', 'execution_count'], 'properties': {'output_type': {'description': 'Type of cell output.', 'enum': ['execute_result']}, 'execution_count': {'description': \"A result's prompt number.\", 'type': ['integer', 'null'], 'minimum': 0}, 'data': {'$ref': '#/definitions/misc/mimebundle'}, 'metadata': {'$ref': '#/definitions/misc/output_metadata'}}}, 'display_data': {'description': 'Data displayed as a result of code cell execution.', 'type': 'object', 'additionalProperties': False, 'required': ['output_type', 'data', 'metadata'], 'properties': {'output_type': {'description': 'Type of cell output.', 'enum': ['display_data']}, 'data': {'$ref': '#/definitions/misc/mimebundle'}, 'metadata': {'$ref': '#/definitions/misc/output_metadata'}}}, 'stream': {'description': 'Stream output from a code cell.', 'type': 'object', 'additionalProperties': False, 'required': ['output_type', 'name', 'text'], 'properties': {'output_type': {'description': 'Type of cell output.', 'enum': ['stream']}, 'name': {'description': 'The name of the stream (stdout, stderr).', 'type': 'string'}, 'text': {'description': \"The stream's text output, represented as an array of strings.\", '$ref': '#/definitions/misc/multiline_string'}}}, 'error': {'description': 'Output of an error that occurred during code cell execution.', 'type': 'object', 'additionalProperties': False, 'required': ['output_type', 'ename', 'evalue', 'traceback'], 'properties': {'output_type': {'description': 'Type of cell output.', 'enum': ['error']}, 'ename': {'description': 'The name of the error.', 'type': 'string'}, 'evalue': {'description': 'The value, or message, of the error.', 'type': 'string'}, 'traceback': {'description': \"The error's traceback, represented as an array of strings.\", 'type': 'array', 'items': {'type': 'string'}}}}, 'unrecognized_output': {'description': 'Unrecognized output from a future minor-revision to the notebook format.', 'type': 'object', 'additionalProperties': True, 'required': ['output_type'], 'properties': {'output_type': {'description': 'Type of cell output.', 'not': {'enum': ['execute_result', 'display_data', 'stream', 'error']}}}}, 'misc': {'metadata_name': {'description': \"The cell's name. If present, must be a non-empty string. Must be unique across all the cells of a given notebook.\", 'type': 'string', 'pattern': '^.+$'}, 'metadata_tags': {'description': \"The cell's tags. Tags must be unique, and must not contain commas.\", 'type': 'array', 'uniqueItems': True, 'items': {'type': 'string', 'pattern': '^[^,]+$'}}, 'attachments': {'description': 'Media attachments (e.g. inline images), stored as mimebundle keyed by filename.', 'type': 'object', 'patternProperties': {'.*': {'description': \"The attachment's data stored as a mimebundle.\", '$ref': '#/definitions/misc/mimebundle'}}}, 'source': {'description': 'Contents of the cell, represented as an array of lines.', '$ref': '#/definitions/misc/multiline_string'}, 'execution_count': {'description': \"The code cell's prompt number. Will be null if the cell has not been run.\", 'type': ['integer', 'null'], 'minimum': 0}, 'mimebundle': {'description': 'A mime-type keyed dictionary of data', 'type': 'object', 'additionalProperties': {'description': 'mimetype output (e.g. text/plain), represented as either an array of strings or a string.', '$ref': '#/definitions/misc/multiline_string'}, 'patternProperties': {'^application/(.*\\\\+)?json$': {'description': 'Mimetypes with JSON output, can be any type'}}}, 'output_metadata': {'description': 'Cell output metadata.', 'type': 'object', 'additionalProperties': True}, 'multiline_string': {'oneOf': [{'type': 'string'}, {'type': 'array', 'items': {'type': 'string'}}]}}}}\n",
      "(4, 2) {(4, 2): Draft4Validator(schema={'$schema': 'http://json-...ft-04/schema#', 'additionalProperties': False, 'definitions': {'cell': {'oneOf': [{'$ref': '#/definitions/raw_cell'}, {'$ref': '#/definitions/markdown_cell'}, {'$ref': '#/definitions/code_cell'}], 'type': 'object'}, 'code_cell': {'additionalProperties': False, 'description': 'Notebook code cell.', 'properties': {'cell_type': {'description': 'String ident...type of cell.', 'enum': ['code']}, 'execution_count': {'description': 'The code cel...not been run.', 'minimum': 0, 'type': ['integer', 'null']}, 'metadata': {'additionalProperties': True, 'description': 'Cell-level metadata.', 'properties': {'collapsed': {...}, 'name': {...}, 'scrolled': {...}, 'tags': {...}}, 'type': 'object'}, 'outputs': {'description': 'Execution, d...ream outputs.', 'items': {'$ref': '#/definitions/output'}, 'type': 'array'}, ...}, 'required': ['cell_type', 'metadata', 'source', 'outputs', 'execution_count'], ...}, 'display_data': {'additionalProperties': False, 'description': 'Data display...ll execution.', 'properties': {'data': {'$ref': '#/definition...sc/mimebundle'}, 'metadata': {'$ref': '#/definition...tput_metadata'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['display_data']}}, 'required': ['output_type', 'data', 'metadata'], ...}, 'error': {'additionalProperties': False, 'description': 'Output of an...ll execution.', 'properties': {'ename': {'description': 'The name of the error.', 'type': 'string'}, 'evalue': {'description': 'The value, o...of the error.', 'type': 'string'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['error']}, 'traceback': {'description': \"The error's ...y of strings.\", 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['output_type', 'ename', 'evalue', 'traceback'], ...}, ...}, 'description': 'Jupyter Note... JSON schema.', ...}, format_checker=None)}\n",
      "(4, 2) {(4, 2): Draft4Validator(schema={'$schema': 'http://json-...ft-04/schema#', 'additionalProperties': True, 'definitions': {'cell': {'oneOf': [{'$ref': '#/definitions/raw_cell'}, {'$ref': '#/definitions/markdown_cell'}, {'$ref': '#/definitions/code_cell'}], 'type': 'object'}, 'code_cell': {'additionalProperties': True, 'description': 'Notebook code cell.', 'properties': {'cell_type': {'description': 'String ident...type of cell.', 'enum': ['code']}, 'execution_count': {'description': 'The code cel...not been run.', 'minimum': 0, 'type': ['integer', 'null']}, 'metadata': {'additionalProperties': True, 'description': 'Cell-level metadata.', 'properties': {'collapsed': {...}, 'name': {...}, 'scrolled': {...}, 'tags': {...}}, 'type': 'object'}, 'outputs': {'description': 'Execution, d...ream outputs.', 'items': {'$ref': '#/definitions/output'}, 'type': 'array'}, ...}, 'required': ['cell_type', 'metadata', 'source', 'outputs', 'execution_count'], ...}, 'display_data': {'additionalProperties': True, 'description': 'Data display...ll execution.', 'properties': {'data': {'$ref': '#/definition...sc/mimebundle'}, 'metadata': {'$ref': '#/definition...tput_metadata'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['display_data']}}, 'required': ['output_type', 'data', 'metadata'], ...}, 'error': {'additionalProperties': True, 'description': 'Output of an...ll execution.', 'properties': {'ename': {'description': 'The name of the error.', 'type': 'string'}, 'evalue': {'description': 'The value, o...of the error.', 'type': 'string'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['error']}, 'traceback': {'description': \"The error's ...y of strings.\", 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['output_type', 'ename', 'evalue', 'traceback'], ...}, ...}, 'description': 'Jupyter Note... JSON schema.', ...}, format_checker=None)}\n",
      "(4, 2) {(4, 2): Draft4Validator(schema={'$schema': 'http://json-...ft-04/schema#', 'additionalProperties': True, 'definitions': {'cell': {'oneOf': [{'$ref': '#/definitions/raw_cell'}, {'$ref': '#/definitions/markdown_cell'}, {'$ref': '#/definitions/code_cell'}], 'type': 'object'}, 'code_cell': {'additionalProperties': True, 'description': 'Notebook code cell.', 'properties': {'cell_type': {'description': 'String ident...type of cell.', 'enum': ['code']}, 'execution_count': {'description': 'The code cel...not been run.', 'minimum': 0, 'type': ['integer', 'null']}, 'metadata': {'additionalProperties': True, 'description': 'Cell-level metadata.', 'properties': {'collapsed': {...}, 'name': {...}, 'scrolled': {...}, 'tags': {...}}, 'type': 'object'}, 'outputs': {'description': 'Execution, d...ream outputs.', 'items': {'$ref': '#/definitions/output'}, 'type': 'array'}, ...}, 'required': ['cell_type', 'metadata', 'source', 'outputs', 'execution_count'], ...}, 'display_data': {'additionalProperties': True, 'description': 'Data display...ll execution.', 'properties': {'data': {'$ref': '#/definition...sc/mimebundle'}, 'metadata': {'$ref': '#/definition...tput_metadata'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['display_data']}}, 'required': ['output_type', 'data', 'metadata'], ...}, 'error': {'additionalProperties': True, 'description': 'Output of an...ll execution.', 'properties': {'ename': {'description': 'The name of the error.', 'type': 'string'}, 'evalue': {'description': 'The value, o...of the error.', 'type': 'string'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['error']}, 'traceback': {'description': \"The error's ...y of strings.\", 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['output_type', 'ename', 'evalue', 'traceback'], ...}, ...}, 'description': 'Jupyter Note... JSON schema.', ...}, format_checker=None)}\n",
      "(4, 2) {(4, 2): Draft4Validator(schema={'$schema': 'http://json-...ft-04/schema#', 'additionalProperties': True, 'definitions': {'cell': {'oneOf': [{'$ref': '#/definitions/raw_cell'}, {'$ref': '#/definitions/markdown_cell'}, {'$ref': '#/definitions/code_cell'}], 'type': 'object'}, 'code_cell': {'additionalProperties': True, 'description': 'Notebook code cell.', 'properties': {'cell_type': {'description': 'String ident...type of cell.', 'enum': ['code']}, 'execution_count': {'description': 'The code cel...not been run.', 'minimum': 0, 'type': ['integer', 'null']}, 'metadata': {'additionalProperties': True, 'description': 'Cell-level metadata.', 'properties': {'collapsed': {...}, 'name': {...}, 'scrolled': {...}, 'tags': {...}}, 'type': 'object'}, 'outputs': {'description': 'Execution, d...ream outputs.', 'items': {'$ref': '#/definitions/output'}, 'type': 'array'}, ...}, 'required': ['cell_type', 'metadata', 'source', 'outputs', 'execution_count'], ...}, 'display_data': {'additionalProperties': True, 'description': 'Data display...ll execution.', 'properties': {'data': {'$ref': '#/definition...sc/mimebundle'}, 'metadata': {'$ref': '#/definition...tput_metadata'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['display_data']}}, 'required': ['output_type', 'data', 'metadata'], ...}, 'error': {'additionalProperties': True, 'description': 'Output of an...ll execution.', 'properties': {'ename': {'description': 'The name of the error.', 'type': 'string'}, 'evalue': {'description': 'The value, o...of the error.', 'type': 'string'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['error']}, 'traceback': {'description': \"The error's ...y of strings.\", 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['output_type', 'ename', 'evalue', 'traceback'], ...}, ...}, 'description': 'Jupyter Note... JSON schema.', ...}, format_checker=None)}\n",
      "(4, 2) {(4, 2): Draft4Validator(schema={'$schema': 'http://json-...ft-04/schema#', 'additionalProperties': True, 'definitions': {'cell': {'oneOf': [{'$ref': '#/definitions/raw_cell'}, {'$ref': '#/definitions/markdown_cell'}, {'$ref': '#/definitions/code_cell'}], 'type': 'object'}, 'code_cell': {'additionalProperties': True, 'description': 'Notebook code cell.', 'properties': {'cell_type': {'description': 'String ident...type of cell.', 'enum': ['code']}, 'execution_count': {'description': 'The code cel...not been run.', 'minimum': 0, 'type': ['integer', 'null']}, 'metadata': {'additionalProperties': True, 'description': 'Cell-level metadata.', 'properties': {'collapsed': {...}, 'name': {...}, 'scrolled': {...}, 'tags': {...}}, 'type': 'object'}, 'outputs': {'description': 'Execution, d...ream outputs.', 'items': {'$ref': '#/definitions/output'}, 'type': 'array'}, ...}, 'required': ['cell_type', 'metadata', 'source', 'outputs', 'execution_count'], ...}, 'display_data': {'additionalProperties': True, 'description': 'Data display...ll execution.', 'properties': {'data': {'$ref': '#/definition...sc/mimebundle'}, 'metadata': {'$ref': '#/definition...tput_metadata'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['display_data']}}, 'required': ['output_type', 'data', 'metadata'], ...}, 'error': {'additionalProperties': True, 'description': 'Output of an...ll execution.', 'properties': {'ename': {'description': 'The name of the error.', 'type': 'string'}, 'evalue': {'description': 'The value, o...of the error.', 'type': 'string'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['error']}, 'traceback': {'description': \"The error's ...y of strings.\", 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['output_type', 'ename', 'evalue', 'traceback'], ...}, ...}, 'description': 'Jupyter Note... JSON schema.', ...}, format_checker=None)}\n",
      "(4, 2) {(4, 2): Draft4Validator(schema={'$schema': 'http://json-...ft-04/schema#', 'additionalProperties': True, 'definitions': {'cell': {'oneOf': [{'$ref': '#/definitions/raw_cell'}, {'$ref': '#/definitions/markdown_cell'}, {'$ref': '#/definitions/code_cell'}], 'type': 'object'}, 'code_cell': {'additionalProperties': True, 'description': 'Notebook code cell.', 'properties': {'cell_type': {'description': 'String ident...type of cell.', 'enum': ['code']}, 'execution_count': {'description': 'The code cel...not been run.', 'minimum': 0, 'type': ['integer', 'null']}, 'metadata': {'additionalProperties': True, 'description': 'Cell-level metadata.', 'properties': {'collapsed': {...}, 'name': {...}, 'scrolled': {...}, 'tags': {...}}, 'type': 'object'}, 'outputs': {'description': 'Execution, d...ream outputs.', 'items': {'$ref': '#/definitions/output'}, 'type': 'array'}, ...}, 'required': ['cell_type', 'metadata', 'source', 'outputs', 'execution_count'], ...}, 'display_data': {'additionalProperties': True, 'description': 'Data display...ll execution.', 'properties': {'data': {'$ref': '#/definition...sc/mimebundle'}, 'metadata': {'$ref': '#/definition...tput_metadata'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['display_data']}}, 'required': ['output_type', 'data', 'metadata'], ...}, 'error': {'additionalProperties': True, 'description': 'Output of an...ll execution.', 'properties': {'ename': {'description': 'The name of the error.', 'type': 'string'}, 'evalue': {'description': 'The value, o...of the error.', 'type': 'string'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['error']}, 'traceback': {'description': \"The error's ...y of strings.\", 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['output_type', 'ename', 'evalue', 'traceback'], ...}, ...}, 'description': 'Jupyter Note... JSON schema.', ...}, format_checker=None)}\n",
      "(4, 2) {(4, 2): Draft4Validator(schema={'$schema': 'http://json-...ft-04/schema#', 'additionalProperties': True, 'definitions': {'cell': {'oneOf': [{'$ref': '#/definitions/raw_cell'}, {'$ref': '#/definitions/markdown_cell'}, {'$ref': '#/definitions/code_cell'}], 'type': 'object'}, 'code_cell': {'additionalProperties': True, 'description': 'Notebook code cell.', 'properties': {'cell_type': {'description': 'String ident...type of cell.', 'enum': ['code']}, 'execution_count': {'description': 'The code cel...not been run.', 'minimum': 0, 'type': ['integer', 'null']}, 'metadata': {'additionalProperties': True, 'description': 'Cell-level metadata.', 'properties': {'collapsed': {...}, 'name': {...}, 'scrolled': {...}, 'tags': {...}}, 'type': 'object'}, 'outputs': {'description': 'Execution, d...ream outputs.', 'items': {'$ref': '#/definitions/output'}, 'type': 'array'}, ...}, 'required': ['cell_type', 'metadata', 'source', 'outputs', 'execution_count'], ...}, 'display_data': {'additionalProperties': True, 'description': 'Data display...ll execution.', 'properties': {'data': {'$ref': '#/definition...sc/mimebundle'}, 'metadata': {'$ref': '#/definition...tput_metadata'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['display_data']}}, 'required': ['output_type', 'data', 'metadata'], ...}, 'error': {'additionalProperties': True, 'description': 'Output of an...ll execution.', 'properties': {'ename': {'description': 'The name of the error.', 'type': 'string'}, 'evalue': {'description': 'The value, o...of the error.', 'type': 'string'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['error']}, 'traceback': {'description': \"The error's ...y of strings.\", 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['output_type', 'ename', 'evalue', 'traceback'], ...}, ...}, 'description': 'Jupyter Note... JSON schema.', ...}, format_checker=None)}\n",
      "(4, 2) {(4, 2): Draft4Validator(schema={'$schema': 'http://json-...ft-04/schema#', 'additionalProperties': True, 'definitions': {'cell': {'oneOf': [{'$ref': '#/definitions/raw_cell'}, {'$ref': '#/definitions/markdown_cell'}, {'$ref': '#/definitions/code_cell'}], 'type': 'object'}, 'code_cell': {'additionalProperties': True, 'description': 'Notebook code cell.', 'properties': {'cell_type': {'description': 'String ident...type of cell.', 'enum': ['code']}, 'execution_count': {'description': 'The code cel...not been run.', 'minimum': 0, 'type': ['integer', 'null']}, 'metadata': {'additionalProperties': True, 'description': 'Cell-level metadata.', 'properties': {'collapsed': {...}, 'name': {...}, 'scrolled': {...}, 'tags': {...}}, 'type': 'object'}, 'outputs': {'description': 'Execution, d...ream outputs.', 'items': {'$ref': '#/definitions/output'}, 'type': 'array'}, ...}, 'required': ['cell_type', 'metadata', 'source', 'outputs', 'execution_count'], ...}, 'display_data': {'additionalProperties': True, 'description': 'Data display...ll execution.', 'properties': {'data': {'$ref': '#/definition...sc/mimebundle'}, 'metadata': {'$ref': '#/definition...tput_metadata'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['display_data']}}, 'required': ['output_type', 'data', 'metadata'], ...}, 'error': {'additionalProperties': True, 'description': 'Output of an...ll execution.', 'properties': {'ename': {'description': 'The name of the error.', 'type': 'string'}, 'evalue': {'description': 'The value, o...of the error.', 'type': 'string'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['error']}, 'traceback': {'description': \"The error's ...y of strings.\", 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['output_type', 'ename', 'evalue', 'traceback'], ...}, ...}, 'description': 'Jupyter Note... JSON schema.', ...}, format_checker=None)}\n",
      "(4, 2) {(4, 2): Draft4Validator(schema={'$schema': 'http://json-...ft-04/schema#', 'additionalProperties': True, 'definitions': {'cell': {'oneOf': [{'$ref': '#/definitions/raw_cell'}, {'$ref': '#/definitions/markdown_cell'}, {'$ref': '#/definitions/code_cell'}], 'type': 'object'}, 'code_cell': {'additionalProperties': True, 'description': 'Notebook code cell.', 'properties': {'cell_type': {'description': 'String ident...type of cell.', 'enum': ['code']}, 'execution_count': {'description': 'The code cel...not been run.', 'minimum': 0, 'type': ['integer', 'null']}, 'metadata': {'additionalProperties': True, 'description': 'Cell-level metadata.', 'properties': {'collapsed': {...}, 'name': {...}, 'scrolled': {...}, 'tags': {...}}, 'type': 'object'}, 'outputs': {'description': 'Execution, d...ream outputs.', 'items': {'$ref': '#/definitions/output'}, 'type': 'array'}, ...}, 'required': ['cell_type', 'metadata', 'source', 'outputs', 'execution_count'], ...}, 'display_data': {'additionalProperties': True, 'description': 'Data display...ll execution.', 'properties': {'data': {'$ref': '#/definition...sc/mimebundle'}, 'metadata': {'$ref': '#/definition...tput_metadata'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['display_data']}}, 'required': ['output_type', 'data', 'metadata'], ...}, 'error': {'additionalProperties': True, 'description': 'Output of an...ll execution.', 'properties': {'ename': {'description': 'The name of the error.', 'type': 'string'}, 'evalue': {'description': 'The value, o...of the error.', 'type': 'string'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['error']}, 'traceback': {'description': \"The error's ...y of strings.\", 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['output_type', 'ename', 'evalue', 'traceback'], ...}, ...}, 'description': 'Jupyter Note... JSON schema.', ...}, format_checker=None)}\n",
      "(4, 2) {(4, 2): Draft4Validator(schema={'$schema': 'http://json-...ft-04/schema#', 'additionalProperties': True, 'definitions': {'cell': {'oneOf': [{'$ref': '#/definitions/raw_cell'}, {'$ref': '#/definitions/markdown_cell'}, {'$ref': '#/definitions/code_cell'}], 'type': 'object'}, 'code_cell': {'additionalProperties': True, 'description': 'Notebook code cell.', 'properties': {'cell_type': {'description': 'String ident...type of cell.', 'enum': ['code']}, 'execution_count': {'description': 'The code cel...not been run.', 'minimum': 0, 'type': ['integer', 'null']}, 'metadata': {'additionalProperties': True, 'description': 'Cell-level metadata.', 'properties': {'collapsed': {...}, 'name': {...}, 'scrolled': {...}, 'tags': {...}}, 'type': 'object'}, 'outputs': {'description': 'Execution, d...ream outputs.', 'items': {'$ref': '#/definitions/output'}, 'type': 'array'}, ...}, 'required': ['cell_type', 'metadata', 'source', 'outputs', 'execution_count'], ...}, 'display_data': {'additionalProperties': True, 'description': 'Data display...ll execution.', 'properties': {'data': {'$ref': '#/definition...sc/mimebundle'}, 'metadata': {'$ref': '#/definition...tput_metadata'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['display_data']}}, 'required': ['output_type', 'data', 'metadata'], ...}, 'error': {'additionalProperties': True, 'description': 'Output of an...ll execution.', 'properties': {'ename': {'description': 'The name of the error.', 'type': 'string'}, 'evalue': {'description': 'The value, o...of the error.', 'type': 'string'}, 'output_type': {'description': 'Type of cell output.', 'enum': ['error']}, 'traceback': {'description': \"The error's ...y of strings.\", 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['output_type', 'ename', 'evalue', 'traceback'], ...}, ...}, 'description': 'Jupyter Note... JSON schema.', ...}, format_checker=None)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Cost_I0869(2).ipynb to script\n",
      "[NbConvertApp] Writing 29550 bytes to Cost_I0869(2).py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "currentNotebook = 'Cost_I0869(2).ipynb'\n",
    "\n",
    "!jupyter nbconvert --to script {currentNotebook} \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['codex_widget_factory']\n",
      "SUCCESS | Submitted config params.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "utils.submit_config_params(url='https://codex-api-stage.azurewebsites.net/codex-api/projects/upload-config-params/SX-c_2CeiRxhDYzfTeHchA', nb_name=currentNotebook, results=results_json, codex_tags=codex_tags, args={})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a43309a6814cada82cd08ad2d74c1595a73ef92ce23ea4875b35adbed179cc64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
